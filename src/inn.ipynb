{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import innvestigate\n",
    "import innvestigate.utils as innutils\n",
    "from matplotlib import pyplot as plt\n",
    "import utils as eutils\n",
    "import utils_mnist as mnistutils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_not_preprocessed = mnistutils.fetch_data()\n",
    "\n",
    "input_range = [-1, 1]\n",
    "preprocess, revert_preprocessing = mnistutils.create_preprocessing_f(data_not_preprocessed[0], input_range)\n",
    "\n",
    "# Preprocess data\n",
    "data = (\n",
    "    preprocess(data_not_preprocessed[0]), data_not_preprocessed[1],\n",
    "    preprocess(data_not_preprocessed[2]), data_not_preprocessed[3]\n",
    ")\n",
    "\n",
    "num_classes = len(np.unique(data[1]))\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.1311 - acc: 0.9598\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0374 - acc: 0.9883\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 89s 1ms/step - loss: 0.0212 - acc: 0.9931\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0152 - acc: 0.9949\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0116 - acc: 0.9962\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0056 - acc: 0.9983\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0062 - acc: 0.9981\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 0.0050 - acc: 0.9983\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 76s 1ms/step - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0049 - acc: 0.9985\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0037 - acc: 0.9989\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0035 - acc: 0.9990\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0035 - acc: 0.9988\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0023 - acc: 0.9995\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.0025 - acc: 0.9994\n",
      "Scores on test set: loss=0.05538101202683947 accuracy=0.9888\n"
     ]
    }
   ],
   "source": [
    "if keras.backend.image_data_format == \"channels_first\":\n",
    "    input_shape = (1, 28, 28)\n",
    "else:\n",
    "    input_shape = (28, 28, 1)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "scores = mnistutils.train_model(model, data, batch_size=128, epochs=20)\n",
    "print(\"Scores on test set: loss=%s accuracy=%s\" % tuple(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale to [0, 1] range for plotting.\n",
    "def input_postprocessing(X):\n",
    "    return revert_preprocessing(X) / 255\n",
    "\n",
    "\n",
    "noise_scale = (input_range[1]-input_range[0]) * 0.1\n",
    "ri = input_range[0]  # reference input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure analysis methods and properties\n",
    "methods = [\n",
    "    # NAME                    OPT.PARAMS                POSTPROC FXN               TITLE\n",
    "\n",
    "    # Show input\n",
    "    (\"input\",                 {},                       input_postprocessing,      \"Input\"),\n",
    "\n",
    "    # Function\n",
    "    (\"gradient\",              {\"postprocess\": \"abs\"},   mnistutils.graymap,        \"Gradient\"),\n",
    "    (\"smoothgrad\",            {\"noise_scale\": noise_scale,\n",
    "                               \"postprocess\": \"square\"},mnistutils.graymap,        \"SmoothGrad\"),\n",
    "\n",
    "    # Signal\n",
    "    (\"deconvnet\",             {},                       mnistutils.bk_proj,        \"Deconvnet\"),\n",
    "    (\"guided_backprop\",       {},                       mnistutils.bk_proj,        \"Guided Backprop\",),\n",
    "    (\"pattern.net\",           {\"pattern_type\": \"relu\"}, mnistutils.bk_proj,        \"PatternNet\"),\n",
    "\n",
    "    # Interaction\n",
    "    (\"pattern.attribution\",   {\"pattern_type\": \"relu\"}, mnistutils.heatmap,        \"PatternAttribution\"),\n",
    "    (\"deep_taylor.bounded\",   {\"low\": input_range[0],\n",
    "                               \"high\": input_range[1]}, mnistutils.heatmap,        \"DeepTaylor\"),\n",
    "    (\"input_t_gradient\",      {},                       mnistutils.heatmap,        \"Input * Gradient\"),\n",
    "    (\"integrated_gradients\",  {\"reference_inputs\": ri}, mnistutils.heatmap,        \"Integrated Gradients\"),\n",
    "    #(\"deep_lift.wrapper\",     {\"reference_inputs\": ri}, mnistutils.heatmap,        \"DeepLIFT Wrapper - Rescale\"),\n",
    "    #(\"deep_lift.wrapper\",     {\"reference_inputs\": ri, \"nonlinear_mode\": \"reveal_cancel\"},\n",
    "    #                                                    mnistutils.heatmap,        \"DeepLIFT Wrapper - RevealCancel\"),\n",
    "    (\"lrp.z\",                 {},                       mnistutils.heatmap,        \"LRP-Z\"),\n",
    "    (\"lrp.epsilon\",           {\"epsilon\": 1},           mnistutils.heatmap,        \"LRP-Epsilon\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "235/235 [==============================] - 73s 309ms/step - loss: 4.0000 - broadcast_9_loss: 1.0000 - broadcast_10_loss: 1.0000 - broadcast_11_loss: 1.0000 - broadcast_12_loss: 1.0000\n",
      "Epoch 1/1\n",
      "235/235 [==============================] - 75s 320ms/step - loss: 4.0000 - broadcast_13_loss: 1.0000 - broadcast_14_loss: 1.0000 - broadcast_15_loss: 1.0000 - broadcast_16_loss: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Create model without trailing softmax\n",
    "model_wo_softmax = innutils.keras.graph.model_wo_softmax(model)\n",
    "\n",
    "# Create analyzers.\n",
    "analyzers = []\n",
    "for method in methods:\n",
    "    analyzer = innvestigate.create_analyzer(\n",
    "        method[0],                     # analysis method identifier\n",
    "        model_wo_softmax,              # model without softmax output\n",
    "        neuron_selection_mode=\"index\", # We want to select the output neuron to analyze.\n",
    "        **method[1])                   # optional analysis parameters\n",
    "\n",
    "    # Some analyzers require training.\n",
    "    analyzer.fit(data[0], batch_size=256, verbose=1)\n",
    "    analyzers.append(analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "project() got an unexpected keyword argument 'input_is_postive_only'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d86d17676736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Apply analysis postprocessing, e.g., creating a heatmap.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Store the analysis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0manalysis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maidx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/COVID-LRP/src/utils_mnist.py\u001b[0m in \u001b[0;36mgraymap\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgraymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mivis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate/utils/visualizations.py\u001b[0m in \u001b[0;36mgraymap\u001b[0;34m(X, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgraymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m\"\"\"Same as :func:`heatmap` but uses a gray colormap.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate/utils/visualizations.py\u001b[0m in \u001b[0;36mheatmap\u001b[0;34m(X, cmap_type, reduce_op, reduce_axis, alpha_cmap, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malpha_cmap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: project() got an unexpected keyword argument 'input_is_postive_only'"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "test_images = list(zip(data[2][:n], data[3][:n]))\n",
    "\n",
    "for image_nr, (x, y) in enumerate(test_images):\n",
    "    # Add batch axis.\n",
    "    x = x[None, :, :, :]\n",
    "\n",
    "    analysis = np.zeros([5, len(analyzers), 28, 28, 3])\n",
    "    text = []\n",
    "\n",
    "    for ii, output_neuron in enumerate([4, 5, 6, 8, 9]): #range(num_classes):\n",
    "        # Predict final activations, probabilites, and label.\n",
    "        presm = model_wo_softmax.predict_on_batch(x)[0]\n",
    "        prob = model.predict_on_batch(x)[0]\n",
    "        y_hat = prob.argmax()\n",
    "\n",
    "        # Save prediction info:\n",
    "        text.append((\"%s\" % label_to_class_name[y],    # ground truth label\n",
    "                     \"%.2f\" % presm[output_neuron],    # pre-softmax logits\n",
    "                     \"%.2f\" % prob[output_neuron],     # probabilistic softmax output  \n",
    "                     \"%s\" % label_to_class_name[output_neuron]\n",
    "                    ))\n",
    "\n",
    "        for aidx, analyzer in enumerate(analyzers):\n",
    "            # Analyze.\n",
    "            a = analyzer.analyze(x, neuron_selection=output_neuron)\n",
    "\n",
    "            # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
    "            a = mnistutils.postprocess(a)\n",
    "            # Apply analysis postprocessing, e.g., creating a heatmap.\n",
    "            a = methods[aidx][2](a)\n",
    "            # Store the analysis.\n",
    "            analysis[ii, aidx] = a[0]\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"Image nr. {}: \".format(image_nr))\n",
    "    # Prepare the grid as rectengular list\n",
    "    grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
    "            for i in range(analysis.shape[0])]\n",
    "    # Prepare the labels\n",
    "    label, presm, prob, pred = zip(*text)\n",
    "    row_labels_left = [('label: {}'.format(label[i]), 'neuron: {}'.format(pred[i])) for i in range(len(label))]\n",
    "    row_labels_right = [('logit: {}'.format(presm[i]), 'prob: {}'.format(prob[i])) for i in range(len(label))]\n",
    "    col_labels = [''.join(method[3]) for method in methods]\n",
    "\n",
    "    # Plot the analysis.\n",
    "    file_name = os.environ.get(\"PLOTFILENAME\", None)\n",
    "    if file_name is not None:\n",
    "        file_name = \".\".join(file_name.split(\".\")[:-1])+(\"_%i\" % output_neuron)+file_name.split(\".\")[-1]\n",
    "    eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels, file_name=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
